{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Neural Network using Keras and Sckit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pp\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv', dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.iloc[:,1:].values\n",
    "y = df_train.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some random data\n",
    "idx = np.random.randint(low=0, high =X.shape[0], size=16)\n",
    "sel = y[idx]\n",
    "sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = X[idx, :]\n",
    "sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayData(X):\n",
    "    width=int(np.round(np.sqrt(X.shape[1])))\n",
    "    (m,n) = X.shape\n",
    "    height = int(n/width)\n",
    "    \n",
    "    display_rows = int(np.floor(np.sqrt(m)))\n",
    "    display_cols = int(np.ceil(m/display_rows))\n",
    "    \n",
    "    fig, axes = pp.subplots( nrows=display_rows, ncols=display_cols, figsize=(20,10))\n",
    "    pp.subplots_adjust(hspace = 0.01, wspace=0.01)\n",
    "    k = 0\n",
    "    for i in range(display_rows):\n",
    "        for j in range(display_cols):\n",
    "            axes[i,j].imshow(X[k].reshape(height, width), cmap='gray')\n",
    "            axes[i,j].set_xticks([])\n",
    "            axes[i,j].set_yticks([])\n",
    "            axes[i,j].set_xticklabels([])\n",
    "            axes[i,j].set_yticklabels([])\n",
    "            k = k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayData(sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First try with a normal ANN (without data augumentation and convolution or regularization)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.transform(X_train)\n",
    "X_cv = scaler.transform(X_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# For Multi class classification we need to one hot encode the labels (outputs)\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_cv = np_utils.to_categorical(y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target number of classes\n",
    "num_classes = y_train.shape[1]\n",
    "\n",
    "# num of pixels\n",
    "num_pixels = X_train.shape[1]\n",
    "\n",
    "# num_samples\n",
    "num_train = X_train.shape[0]\n",
    "num_cv = X_cv.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming a square image\n",
    "width = np.sqrt(num_pixels).astype(np.int32)\n",
    "height = int(num_pixels/width)\n",
    "\n",
    "# reshape our inputs for image augumentation and convolutions\n",
    "# format (num_samples, )\n",
    "X_train = X_train.reshape((num_train, 1, height, width))\n",
    "X_cv = X_cv.reshape((num_cv, 1, height, width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augumentation using Image Generator\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    shear_range=0.2,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    data_format='channels_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit our generator to training set\n",
    "datagen.fit(X_train, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required classes for our model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29400, 1, 28, 28)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The network topology</b>\n",
    "1. Convolutional layer with 30 feature maps of size 5×5.\n",
    "2. Pooling layer taking the max over 2*2 patches.\n",
    "3. Convolutional layer with 15 feature maps of size 3×3.\n",
    "4. Pooling layer taking the max over 2*2 patches.\n",
    "5. Dropout layer with a probability of 20%.\n",
    "6. Flatten layer.\n",
    "7. Fully connected layer with 128 neurons and rectifier activation.\n",
    "8. Fully connected layer with 50 neurons and rectifier activation.\n",
    "9. Output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDeepModel():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,(5,5), strides=(1,1),activation='relu', data_format='channels_first', input_shape=(1, height, width)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(1,1)))\n",
    "    #model.add(Conv2D(16, (3,3), strides=(1,1), activation='relu', data_format='channels_first'))\n",
    "    #model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu',kernel_initializer='normal'))\n",
    "    #model.add(Dense(64, activation='relu', kernel_initializer='normal'))\n",
    "    model.add(Dense(num_classes, activation='softmax', kernel_initializer='normal'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit our model to our image generator\n",
    "model= createDeepModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29400 samples, validate on 12600 samples\n",
      "Epoch 1/10\n",
      " - 73s - loss: 0.7109 - acc: 0.7985 - val_loss: 0.2624 - val_acc: 0.9262\n",
      "Epoch 2/10\n",
      " - 72s - loss: 0.2068 - acc: 0.9410 - val_loss: 0.1578 - val_acc: 0.9563\n",
      "Epoch 3/10\n",
      " - 72s - loss: 0.1294 - acc: 0.9638 - val_loss: 0.1186 - val_acc: 0.9677\n",
      "Epoch 4/10\n",
      " - 72s - loss: 0.0925 - acc: 0.9732 - val_loss: 0.0975 - val_acc: 0.9721\n",
      "Epoch 5/10\n",
      " - 73s - loss: 0.0716 - acc: 0.9804 - val_loss: 0.0859 - val_acc: 0.9755\n",
      "Epoch 6/10\n",
      " - 72s - loss: 0.0581 - acc: 0.9837 - val_loss: 0.0763 - val_acc: 0.9779\n",
      "Epoch 7/10\n",
      " - 72s - loss: 0.0487 - acc: 0.9866 - val_loss: 0.0749 - val_acc: 0.9777\n",
      "Epoch 8/10\n",
      " - 72s - loss: 0.0421 - acc: 0.9880 - val_loss: 0.0730 - val_acc: 0.9793\n",
      "Epoch 9/10\n",
      " - 72s - loss: 0.0366 - acc: 0.9891 - val_loss: 0.0708 - val_acc: 0.9795\n",
      "Epoch 10/10\n",
      " - 72s - loss: 0.0318 - acc: 0.9909 - val_loss: 0.0676 - val_acc: 0.9810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24e49730a58>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try without Augumentation first\n",
    "model.fit(X_train, y_train, batch_size=1000, epochs=10, verbose=2, validation_data=(X_cv, y_cv), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size = 100\n",
    "#model.fit_generator(datagen.flow(X_train, y_train, batch_size=1000), \\\n",
    "                    steps_per_epoch= 3000, epochs=10, verbose=2, validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
